<<<<<<< HEAD
# MinerÃ­a de Datos â€“ Proyecto Final
# ðŸ“Œ DescripciÃ³n del Proyecto

Este proyecto analiza datos de ventas y productos para identificar clientes VIP y segmentar productos, utilizando tÃ©cnicas de Data Mining y Machine Learning.
Se aplicÃ³ la metodologÃ­a CRISP-DM para guiar todo el flujo de trabajo, desde la comprensiÃ³n del negocio hasta el despliegue de modelos.

## ðŸ“Š Objetivos

Analizar el comportamiento de ventas y descuentos.

Identificar clientes con potencial de convertirse en VIP.

Segmentar productos mediante clustering.

Desarrollar un API que permita predecir clientes VIP y asignar clusters automÃ¡ticamente.

## ðŸ” MetodologÃ­a CRISP-DM

1. ComprensiÃ³n del negocio
Entender las necesidades de la empresa: identificar clientes VIP y optimizar estrategias de ventas y descuentos.

2. ComprensiÃ³n de los datos
Se trabajaron cuatro datasets (Annex1 a Annex4) con informaciÃ³n de productos, ventas y precios mayoristas.

3. PreparaciÃ³n de los datos

    Limpieza de nulos y duplicados.

    CorrecciÃ³n de cantidades negativas y normalizaciÃ³n de columnas categÃ³ricas.

    CÃ¡lculo de nuevas mÃ©tricas: Revenue, Margin y columna VIP segÃºn cuartil 75 de Revenue.

4. AnÃ¡lisis exploratorio de datos (EDA)

    IdentificaciÃ³n de top productos y categorÃ­as.

    VisualizaciÃ³n de precios, pÃ©rdidas, descuentos y ventas por fecha.

5. Modelado

    Modelos principales para predecir clientes VIP: RandomForest y XGBoost (se selecciona el mejor segÃºn AUC-ROC).

    Modelos secundarios obligatorios: SVM (secundario para mostrar cumplimiento del requerimiento).

    Clustering de productos: K-Means (para segmentaciÃ³n de productos).

6. EvaluaciÃ³n

    MÃ©tricas: Accuracy, F1-score, AUC-ROC para clasificaciÃ³n.

    Silhouette Score para K-Means.

7. Despliegue

    Guardado de modelos y preprocesadores (scaler y LabelEncoders) con joblib.

    API construida en Flask para predicciÃ³n en tiempo real.


## âš™ï¸ Requisitos e InstalaciÃ³n

Python 3.12 recomendado, con librerÃ­as:

pip install pandas numpy matplotlib seaborn scikit-learn xgboost flask joblib

## ðŸš€ Uso de la API

Ejecutar api.py: python api.py

Enviar peticiones POST con los datos del cliente/producto para recibir predicciones:

    Probabilidad de ser VIP (modelo principal).

    Probabilidad secundaria con SVM.

    Cluster asignado por K-Means.


## ðŸ“ˆ ExplicaciÃ³n de Modelos

    RandomForest/XGBoost: Modelado principal para predicciÃ³n VIP, se selecciona el mejor segÃºn AUC

    SVM: Modelo secundario, obligatorio segÃºn requerimientos, sirve como referencia de clasificaciÃ³n

    K-Means: SegmentaciÃ³n de productos segÃºn caracterÃ­sticas y ventas, usado para clustering 

## ðŸ“Œ Notas importantes

    El dataset final estÃ¡ limpio y listo para anÃ¡lisis o despliegue.


    Los modelos se entrenan con un subsample de 13k registros para acelerar el entrenamiento sin perder representatividad.

## Enlace Colab
https://colab.research.google.com/drive/1ZIP-udCF2yvgSkrtQefxjKo2I7sqJrF5?usp=sharing
=======
# MinerÃ­a de Datos â€“ Proyecto Final
# ðŸ“Œ DescripciÃ³n del Proyecto

Este proyecto analiza datos de ventas y productos para identificar clientes VIP y segmentar productos, utilizando tÃ©cnicas de Data Mining y Machine Learning.
Se aplicÃ³ la metodologÃ­a CRISP-DM para guiar todo el flujo de trabajo, desde la comprensiÃ³n del negocio hasta el despliegue de modelos.

## ðŸ“Š Objetivos

Analizar el comportamiento de ventas y descuentos.

Identificar clientes con potencial de convertirse en VIP.

Segmentar productos mediante clustering.

Desarrollar un API que permita predecir clientes VIP y asignar clusters automÃ¡ticamente.

## ðŸ” MetodologÃ­a CRISP-DM

1. ComprensiÃ³n del negocio
Entender las necesidades de la empresa: identificar clientes VIP y optimizar estrategias de ventas y descuentos.

2. ComprensiÃ³n de los datos
Se trabajaron cuatro datasets (Annex1 a Annex4) con informaciÃ³n de productos, ventas y precios mayoristas.

3. PreparaciÃ³n de los datos

    Limpieza de nulos y duplicados.

    CorrecciÃ³n de cantidades negativas y normalizaciÃ³n de columnas categÃ³ricas.

    CÃ¡lculo de nuevas mÃ©tricas: Revenue, Margin y columna VIP segÃºn cuartil 75 de Revenue.

4. AnÃ¡lisis exploratorio de datos (EDA)

    IdentificaciÃ³n de top productos y categorÃ­as.

    VisualizaciÃ³n de precios, pÃ©rdidas, descuentos y ventas por fecha.

5. Modelado

    Modelos principales para predecir clientes VIP: RandomForest y XGBoost (se selecciona el mejor segÃºn AUC-ROC).

    Modelos secundarios obligatorios: SVM (secundario para mostrar cumplimiento del requerimiento).

    Clustering de productos: K-Means (para segmentaciÃ³n de productos).

6. EvaluaciÃ³n

    MÃ©tricas: Accuracy, F1-score, AUC-ROC para clasificaciÃ³n.

    Silhouette Score para K-Means.

7. Despliegue

    Guardado de modelos y preprocesadores (scaler y LabelEncoders) con joblib.

    API construida en Flask para predicciÃ³n en tiempo real.


## âš™ï¸ Requisitos e InstalaciÃ³n

Python 3.12 recomendado, con librerÃ­as:

pip install pandas numpy matplotlib seaborn scikit-learn xgboost flask joblib

## ðŸš€ Uso de la API

Ejecutar api.py: python api.py

Enviar peticiones POST con los datos del cliente/producto para recibir predicciones:

    Probabilidad de ser VIP (modelo principal).

    Probabilidad secundaria con SVM.

    Cluster asignado por K-Means.


## ðŸ“ˆ ExplicaciÃ³n de Modelos

    RandomForest/XGBoost: Modelado principal para predicciÃ³n VIP, se selecciona el mejor segÃºn AUC

    SVM: Modelo secundario, obligatorio segÃºn requerimientos, sirve como referencia de clasificaciÃ³n

    K-Means: SegmentaciÃ³n de productos segÃºn caracterÃ­sticas y ventas, usado para clustering 

## ðŸ“Œ Notas importantes

    El dataset final estÃ¡ limpio y listo para anÃ¡lisis o despliegue.


    Los modelos se entrenan con un subsample de 13k registros para acelerar el entrenamiento sin perder representatividad.

## Enlace Colab
https://colab.research.google.com/drive/1ZIP-udCF2yvgSkrtQefxjKo2I7sqJrF5?usp=sharing
>>>>>>> 9881079d7a67111fa900df6bbbf3bbc7f4eb9f2f
